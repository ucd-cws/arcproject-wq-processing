{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Water Quality CSV Transects joined by TIME/DATE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "from wq_gps_match import timestamp_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andy\\Documents\\arcproject-wq-processing\\wq_gps_match\\examples\\Apr_2013\\SummaryFiles\\Apr2013_GPS\\Arc_Apr2013_PosnPnt.shp\n",
      "C:\\Users\\Andy\\Documents\\arcproject-wq-processing\\wq_gps_match\\examples\\Apr_2013\\Arc_040213\\Arc_040213_WQ\\Arc_040213_wqt_sh_2.csv\n"
     ]
    }
   ],
   "source": [
    "# set wd to Arcproject-wq-processing folder\n",
    "wd = os.path.abspath(os.path.join(os.path.dirname(os.path.dirname(\"__file__\"))))\n",
    "# example shp\n",
    "shp = os.path.join(wd, \"wq_gps_match\", \"examples\", \"Apr_2013\", \"SummaryFiles\", \"Apr2013_GPS\", \"Arc_Apr2013_PosnPnt.shp\")\n",
    "\n",
    "# example water quality\n",
    "wq_file = os.path.join(wd, \"wq_gps_match\", \"examples\", \"Apr_2013\", \"Arc_040213\", \"Arc_040213_WQ\", \"Arc_040213_wqt_sh_2.csv\")\n",
    "\n",
    "print(shp)\n",
    "print(wq_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import CSV file from the MiniSonde as Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date_Time   Temp    pH SpCond   Sal   DO%    DO DEP25  PAR RPAR  \\\n",
      "1 2013-04-02 09:18:19  15.87  7.77   2809  1.51  87.9  7.15  0.23  529  610   \n",
      "2 2013-04-02 09:18:20  15.87  7.77   2809  1.51  87.9  7.15  0.23  529  610   \n",
      "3 2013-04-02 09:18:21  15.87  7.76   2809  1.51  88.0  7.17  0.21  527  610   \n",
      "4 2013-04-02 09:18:22  15.87  7.76   2813  1.52  88.0  7.17  0.21  527  610   \n",
      "5 2013-04-02 09:18:23  15.87  7.77   2813  1.52  88.1  7.17  0.22  536  610   \n",
      "\n",
      "  TurbSC   CHL    CHL.1                WQ_SOURCE  \n",
      "1   37.7  5.36  0.05174  Arc_040213_wqt_sh_2.csv  \n",
      "2   37.7  5.36  0.05174  Arc_040213_wqt_sh_2.csv  \n",
      "3   37.6  5.39  0.05200  Arc_040213_wqt_sh_2.csv  \n",
      "4   37.6  5.39  0.05200  Arc_040213_wqt_sh_2.csv  \n",
      "5   37.9  5.42  0.05216  Arc_040213_wqt_sh_2.csv  \n"
     ]
    }
   ],
   "source": [
    "water_quality = timestamp_match.wq_from_csv(wq_file)\n",
    "print(water_quality.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       GPS_Date    GPS_Time           Date_Time              POINT_X  \\\n",
      "0  [2013, 4, 4]  08:18:47am 2013-04-04 08:18:47  -1.21675981849e+002   \n",
      "1  [2013, 4, 4]  08:18:48am 2013-04-04 08:18:48  -1.21675986001e+002   \n",
      "2  [2013, 4, 4]  08:18:49am 2013-04-04 08:18:49  -1.21675990421e+002   \n",
      "3  [2013, 4, 4]  08:18:50am 2013-04-04 08:18:50  -1.21675994058e+002   \n",
      "4  [2013, 4, 4]  08:18:51am 2013-04-04 08:18:51  -1.21675997428e+002   \n",
      "\n",
      "              POINT_Y                               XY  \\\n",
      "0  3.82332247674e+001  [-121.675981849, 38.2332247674]   \n",
      "1  3.82332196115e+001  [-121.675986001, 38.2332196115]   \n",
      "2  3.82332143150e+001   [-121.675990421, 38.233214315]   \n",
      "3  3.82332090390e+001   [-121.675994058, 38.233209039]   \n",
      "4  3.82332039378e+001  [-121.675997428, 38.2332039378]   \n",
      "\n",
      "                GPS_SOURCE  \n",
      "0  Arc_Apr2013_PosnPnt.shp  \n",
      "1  Arc_Apr2013_PosnPnt.shp  \n",
      "2  Arc_Apr2013_PosnPnt.shp  \n",
      "3  Arc_Apr2013_PosnPnt.shp  \n",
      "4  Arc_Apr2013_PosnPnt.shp  \n"
     ]
    }
   ],
   "source": [
    "shp_df = timestamp_match.shp2dataframe(shp)\n",
    "\n",
    "print(shp_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions - origninal WQ:  (1921, 14),  Matches: (1921, 20)\n",
      "Number of rows different: 0\n",
      "Percent Match: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "merged = timestamp_match.JoinByTimeStamp(water_quality, shp_df)\n",
    "#print(merged)\n",
    "\n",
    "matches = merged[0]\n",
    "\n",
    "print('Dimensions - origninal WQ:  {},  Matches: {}'.format( water_quality.shape, matches.shape))\n",
    "\n",
    "print('Number of rows different: {}'.format(water_quality.shape[0] - matches.shape[0]))\n",
    "\n",
    "percent_match = timestamp_match.JoinMatchPercent(water_quality, matches)\n",
    "\n",
    "print('Percent Match: {} %'.format(percent_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# adjust date time by an hour to account for uncorrected daylight savings time\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "def dstadjustment(df, offset_hours):\n",
    "    df2 = df.copy() # make a copy of data so original is not overwritten\n",
    "    dstshift = lambda x: x + timedelta(hours=offset_hours)\n",
    "    df2['Date_Time'] = df2['Date_Time'].map(dstshift)\n",
    "    return df2\n",
    "\n",
    "\n",
    "\n",
    "#orignal = timestamp_match.JoinByTimeStamp(water_quality, shp_df)\n",
    "#percent_match = timestamp_match.JoinMatchPercent(water_quality, matches)\n",
    "\n",
    "\n",
    "#plus1 = dstadjustment(water_quality, 1)\n",
    "\n",
    "offsets= {}\n",
    "\n",
    "for i in [-1,-0.5, 0, 0.5,1]:\n",
    "    print(\"Time offset: {} hour\".format(i))\n",
    "    \n",
    "    # offset water quality\n",
    "    off = dstadjustment(water_quality, i)\n",
    "    \n",
    "    # try joining by timestamp\n",
    "    matches = timestamp_match.JoinByTimeStamp(off, shp_df)[0]\n",
    "    \n",
    "    # report the percentage matched\n",
    "    percent_match = timestamp_match.JoinMatchPercent(water_quality, matches)\n",
    "    print(\"{} %\".format(percent_match))\n",
    "    \n",
    "    # add to dict\n",
    "    offsets[i]=percent_match\n",
    "\n",
    "print(offsets)\n",
    "highest_percent_offset = max(offsets, key=offsets.get)\n",
    "print(highest_percent_offset)\n",
    "\n",
    "\n",
    "offset_df = timestamp_match.dstadjustment(water_quality, highest_percent_offset)\n",
    "offset_df.head()\n",
    "\n",
    "# join using time stamps w/ exact matchjoined_data = timestamp_match.JoinByTimeStamp(offset_df, pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transect_join_timestamp - batch function to combine transect water quality with GPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_data = timestamp_match.transect_join_timestamp(wq_file, shp)\n",
    "print(joined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save to shapefile\n",
    "\n",
    "timestamp_match.main(wq_file, shp, \"Example.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ZOOP CHL W points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set wd to Arcproject-wq-processing folder\n",
    "wd = os.path.abspath(os.path.join(os.path.dirname(os.path.dirname(\"__file__\"))))\n",
    "# shapefile of the Chl sampling locations\n",
    "station_shp = os.path.join(wd, \"wq_gps_match\", \"examples\", \"Arc_040413_GPS\", \"040413_ZoopChlW.shp\")\n",
    "# water quality vertical profile for a Chl sampling point\n",
    "station_wq_file = os.path.join(wd, \"wq_gps_match\", \"examples\", \"Arc_040413_WQ\", \"Arc_040413_wqp_ca1.csv\")\n",
    "\n",
    "print(station_shp)\n",
    "print(station_wq_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's process that water quality at the stationary point\n",
    "station_water_quality = timestamp_match.wq_from_csv(station_wq_file)\n",
    "print(station_water_quality.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's get the shapefile for the stationary points collected that day.\n",
    "\n",
    "station_shp_df = timestamp_match.shp2dataframe(station_shp)\n",
    "\n",
    "print(station_shp_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine the GPS_date and GPS time fields to match a timestamp to use as join field\n",
    "timestamp_match.addCombinedDateTime(station_shp_df, \"GPS_Date\", \"GPS_Time\")\n",
    "print(station_shp_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for each row in the water quality dataframe join the station in if it's with xx minutes. \n",
    "station_gps_datetimes = station_shp_df[\"Date_Time\"].tolist()\n",
    "print(station_gps_datetimes)\n",
    "\n",
    "# for each row find the closest time stamp\n",
    "\n",
    "\n",
    "import datetime\n",
    "\n",
    "ex = station_water_quality[\"Date_Time\"][10]\n",
    "print(\"example: {}\".format(ex))\n",
    "\n",
    "\n",
    "\n",
    "row_time = ex\n",
    "print(\"Test: {}\".format(row_time))\n",
    "\n",
    "\n",
    "def my_minimum(iterable):\n",
    "    iterable = iter(iterable)\n",
    "    minimum = iterable.next()\n",
    "    for i in iterable:\n",
    "        if i < minimum:\n",
    "            minimum = i\n",
    "    return minimum\n",
    "\n",
    "print(my_minimum(station_gps_datetimes))\n",
    "\n",
    "\n",
    "def find_closest_time(row_time, list_of_potential_matches):\n",
    "    iterable = iter(list_of_potential_matches)\n",
    "    minimum = iterable.next()\n",
    "    for t = iterable\n",
    "\n",
    "    for sample_time in list_of_potential_matches:\n",
    "        diff = (row_time - sample_time)\n",
    "        \n",
    "        if diff < 1:\n",
    "            closest_time = sample_time\n",
    "            gap = diff\n",
    "        print(gap)\n",
    "            \n",
    "    # check if closest time is 1 hour        \n",
    "    if gap == datetime.timedelta(hours=1):\n",
    "        return \"No Match\"\n",
    "    else:\n",
    "        return closest_time\n",
    "\n",
    "print(find_closest_time(row_time, station_gps_datetimes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
